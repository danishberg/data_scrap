#!/usr/bin/env python3
"""
GOOGLE HELPER - –ü—Ä–æ—Å—Ç–æ–π –ø–æ–º–æ—â–Ω–∏–∫ –¥–ª—è Google –ø–∞—Ä—Å–∏–Ω–≥–∞
–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ JavaScript —Å–∫—Ä–∏–ø—Ç–∞
"""

import json
import os
import requests
from bs4 import BeautifulSoup
import re
import time
import logging

class GoogleHelper:
    def __init__(self):
        self.logger = logging.getLogger('GoogleHelper')
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ç–µ–ª–µ—Ñ–æ–Ω–æ–≤
        self.phone_patterns = [
            re.compile(r'tel:[\s]*\+?1?[\s]*(\d{3})[\s]*(\d{3})[\s]*(\d{4})'),
            re.compile(r'(\d{3})[^\d]*(\d{3})[^\d]*(\d{4})'),
            re.compile(r'call[\s]*:?[\s]*(\d{3})[\s]*[^\d]*(\d{3})[\s]*[^\d]*(\d{4})')
        ]

    def show_instructions(self):
        """–ü–æ–∫–∞–∑–∞—Ç—å –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –¥–ª—è Google –ø–∞—Ä—Å–∏–Ω–≥–∞"""
        print("\n" + "="*70)
        print("üîç GOOGLE –ü–ê–†–°–ò–ù–ì - –ò–ù–°–¢–†–£–ö–¶–ò–ò")
        print("="*70)
        print("1. –û—Ç–∫—Ä–æ–π—Ç–µ –±—Ä–∞—É–∑–µ—Ä –∏ –ø–µ—Ä–µ–π–¥–∏—Ç–µ –Ω–∞ google.com")
        print("2. –ü–æ–∏—Å–∫: 'scrap metal recycling [–≤–∞—à –≥–æ—Ä–æ–¥]'")
        print("3. –ü–µ—Ä–µ–π–¥–∏—Ç–µ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã 2-5 (–∫–æ–º–ø–∞–Ω–∏–∏ —Å –Ω–∏–∑–∫–∏–º–∏ –ø–æ–∑–∏—Ü–∏—è–º–∏)")
        print("4. F12 ‚Üí Console, –≤—Å—Ç–∞–≤—å—Ç–µ —ç—Ç–æ—Ç JavaScript:")
        print("\n" + "-"*50)
        print(self.get_js_script())
        print("-"*50)
        print("\n5. –°–∫–æ–ø–∏—Ä—É–π—Ç–µ JSON –∏–∑ –æ–∫–Ω–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–∏—Ç–µ –∫–∞–∫ 'google_links.json'")
        print("6. –ó–∞–ø—É—Å—Ç–∏—Ç–µ: python google_helper.py")
        print("="*70)

    def get_js_script(self):
        """–ü–æ–ª—É—á–∏—Ç—å JavaScript —Å–∫—Ä–∏–ø—Ç –¥–ª—è Google"""
        return '''
javascript:!(function(){
    console.log('üîç –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ Google —Å—Å—ã–ª–æ–∫...');
    window.scrollTo(0, document.body.scrollHeight);
    
    var win = window.open('', 'ScrapLinks', 'width=1000,height=800');
    win.document.write('<h2>üìû Scrap Metal Links</h2>');
    
    var results = [];
    var processed = new Set();
    
    [].forEach.call(document.getElementsByClassName('MjjYud'), function(item, index) {
        var link = item.querySelector('a');
        var href = link && (link.getAttribute('data-href') || link.getAttribute('href'));
        var title = link && link.querySelector('h3');
        
        if (href && title && !processed.has(href) && href.indexOf('http') === 0) {
            processed.add(href);
            var titleText = title.innerText || '';
            var text = titleText.toLowerCase();
            
            // –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ scrap metal
            if (text.includes('scrap') || text.includes('metal') || text.includes('recycling') || 
                text.includes('salvage') || text.includes('junk')) {
                
                results.push({
                    url: href,
                    title: titleText,
                    position: index + 1
                });
                
                win.document.write('<div><strong>' + (index + 1) + '</strong> ' + titleText + '<br>');
                win.document.write('<a href="' + href + '">' + href + '</a><br><br></div>');
            }
        }
    });
    
    win.document.write('<hr><h3>JSON:</h3>');
    win.document.write('<textarea rows="10" cols="80" onclick="this.select()">' + 
                      JSON.stringify(results, null, 2) + '</textarea>');
    win.document.write('<p><b>–ù–∞–π–¥–µ–Ω–æ: ' + results.length + '</b></p>');
    
    console.log('‚úÖ –ì–æ—Ç–æ–≤–æ:', results.length);
})();
        '''

    def process_google_links(self, json_file="google_links.json"):
        """–û–±—Ä–∞–±–æ—Ç–∞—Ç—å —Å—Å—ã–ª–∫–∏ –∏–∑ Google"""
        if not os.path.exists(json_file):
            print(f"‚ùå –§–∞–π–ª {json_file} –Ω–µ –Ω–∞–π–¥–µ–Ω")
            print("–°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ Google –ø–∞—Ä—Å–∏–Ω–≥ –ø–æ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏")
            return []
        
        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                links = json.load(f)
            
            print(f"üìÇ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(links)} —Å—Å—ã–ª–æ–∫")
            
            businesses = []
            for i, link in enumerate(links, 1):
                print(f"üîç –û–±—Ä–∞–±–æ—Ç–∫–∞ {i}/{len(links)}: {link.get('title', 'Unknown')}")
                
                business = self._extract_from_url(link)
                if business:
                    businesses.append(business)
                    print(f"  ‚úÖ –ù–∞–π–¥–µ–Ω —Ç–µ–ª–µ—Ñ–æ–Ω: {business.get('phone', '–ù–ï–¢')}")
                else:
                    print(f"  ‚ùå –¢–µ–ª–µ—Ñ–æ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω")
                
                # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
                time.sleep(1)
            
            print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç: {len(businesses)} –±–∏–∑–Ω–µ—Å–æ–≤ —Å —Ç–µ–ª–µ—Ñ–æ–Ω–∞–º–∏")
            return businesses
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
            return []

    def _extract_from_url(self, link_data):
        """–ò–∑–≤–ª–µ—á—å –¥–∞–Ω–Ω—ã–µ –±–∏–∑–Ω–µ—Å–∞ —Å URL"""
        url = link_data.get('url', '')
        if not url:
            return None
        
        try:
            response = self.session.get(url, timeout=15)
            if response.status_code != 200:
                return None
            
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # –ò—â–µ–º —Ç–µ–ª–µ—Ñ–æ–Ω
            phone = self._find_phone_on_page(response.text, soup)
            if not phone:
                return None
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥—Ä—É–≥–∏–µ –¥–∞–Ω–Ω—ã–µ
            business = {
                'name': link_data.get('title', 'Unknown'),
                'website': url,
                'phone': phone,
                'email': self._find_email(response.text),
                'address': self._find_address(soup),
                'source': 'Google',
                'google_position': link_data.get('position', 0)
            }
            
            return business
            
        except Exception as e:
            self.logger.debug(f"–û—à–∏–±–∫–∞ —Å {url}: {e}")
            return None

    def _find_phone_on_page(self, text, soup):
        """–ù–∞–π—Ç–∏ —Ç–µ–ª–µ—Ñ–æ–Ω –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ"""
        # –°–Ω–∞—á–∞–ª–∞ –∏—â–µ–º tel: —Å—Å—ã–ª–∫–∏
        tel_links = soup.find_all('a', href=lambda x: x and x.startswith('tel:'))
        for link in tel_links:
            phone = self._clean_phone(link.get('href', '').replace('tel:', ''))
            if phone:
                return phone
        
        # –ü–æ—Ç–æ–º –∏—â–µ–º –≤ —Ç–µ–∫—Å—Ç–µ
        for pattern in self.phone_patterns:
            matches = pattern.findall(text)
            for match in matches:
                phone = self._format_phone(match)
                if phone:
                    return phone
        
        return ""

    def _find_email(self, text):
        """–ù–∞–π—Ç–∏ email –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ"""
        pattern = re.compile(r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b')
        emails = pattern.findall(text)
        
        for email in emails:
            if not any(skip in email.lower() for skip in ['example', 'test', 'google']):
                return email
        return ""

    def _find_address(self, soup):
        """–ù–∞–π—Ç–∏ –∞–¥—Ä–µ—Å –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ"""
        selectors = ['.address', '.location', '[itemprop="streetAddress"]']
        
        for selector in selectors:
            element = soup.select_one(selector)
            if element:
                return element.get_text().strip()[:100]
        
        return ""

    def _format_phone(self, match):
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–ª–µ—Ñ–æ–Ω"""
        if isinstance(match, tuple) and len(match) >= 3:
            return f"({match[0]}) {match[1]}-{match[2]}"
        return ""

    def _clean_phone(self, phone):
        """–û—á–∏—Å—Ç–∏—Ç—å —Ç–µ–ª–µ—Ñ–æ–Ω"""
        if not phone:
            return ""
        
        digits = re.sub(r'\D', '', phone)
        
        if len(digits) == 10:
            return f"({digits[:3]}) {digits[3:6]}-{digits[6:]}"
        elif len(digits) == 11 and digits[0] == '1':
            return f"({digits[1:4]}) {digits[4:7]}-{digits[7:]}"
        
        return ""

    def save_results(self, businesses, filename="google_results.json"):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã"""
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(businesses, f, indent=2, ensure_ascii=False)
        
        print(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {filename}")

def main():
    print("üîç GOOGLE HELPER - –û–±—Ä–∞–±–æ—Ç–∫–∞ Google —Å—Å—ã–ª–æ–∫")
    print("=" * 50)
    
    helper = GoogleHelper()
    
    choice = input("\n1. –ü–æ–∫–∞–∑–∞—Ç—å –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏\n2. –û–±—Ä–∞–±–æ—Ç–∞—Ç—å —Å—Å—ã–ª–∫–∏\n–í—ã–±–æ—Ä: ")
    
    if choice == "1":
        helper.show_instructions()
    elif choice == "2":
        businesses = helper.process_google_links()
        if businesses:
            helper.save_results(businesses)
            print(f"\nüéâ –ù–∞–π–¥–µ–Ω–æ {len(businesses)} –±–∏–∑–Ω–µ—Å–æ–≤ —Å —Ç–µ–ª–µ—Ñ–æ–Ω–∞–º–∏!")
        else:
            print("\n‚ùå –ë–∏–∑–Ω–µ—Å—ã —Å —Ç–µ–ª–µ—Ñ–æ–Ω–∞–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
    else:
        print("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –≤—ã–±–æ—Ä")

if __name__ == "__main__":
    main() 
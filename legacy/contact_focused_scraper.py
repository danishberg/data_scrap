#!/usr/bin/env python3
"""
Contact-Focused Scraper - –ê–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–π —Å–±–æ—Ä –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤ –¥–ª—è scrap metal —Ü–µ–Ω—Ç—Ä–æ–≤
–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: –∫–æ–Ω—Ç–∞–∫—Ç—ã > –≤—Å–µ –æ—Å—Ç–∞–ª—å–Ω–æ–µ
–°—Ç—Ä–∞—Ç–µ–≥–∏—è: Google –ø–∞—Ä—Å–∏–Ω–≥ –¥–ª—è –∫–æ–º–ø–∞–Ω–∏–π —Å –Ω–∏–∑–∫–∏–º–∏ –ø–æ–∑–∏—Ü–∏—è–º–∏
"""

import os
import sys
import json
import time
import random
import logging
import requests
from bs4 import BeautifulSoup
from datetime import datetime
import pandas as pd
from urllib.parse import quote_plus, urljoin, unquote
import re
from concurrent.futures import ThreadPoolExecutor, as_completed
import asyncio
import aiohttp
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from typing import List, Dict, Any, Optional

class ContactFocusedScraper:
    def __init__(self):
        self.session = requests.Session()
        self.results = []
        self.logger = self._setup_logging()
        
        # –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –ù–ê–°–¢–†–û–ô–ö–ê: –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø—Ä–æ—Ü–µ–Ω—Ç –±–∏–∑–Ω–µ—Å–æ–≤ —Å –∫–æ–Ω—Ç–∞–∫—Ç–∞–º–∏
        self.MIN_CONTACT_PERCENTAGE = 80  # –¶–µ–ª—å: 80%+ –±–∏–∑–Ω–µ—Å–æ–≤ —Å —Ç–µ–ª–µ—Ñ–æ–Ω–∞–º–∏
        
        # –ö–ª—é—á–µ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ –≥–ª—É–±–∏–Ω–Ω—ã—Ö –∫–æ–º–ø–∞–Ω–∏–π
        self.deep_search_queries = [
            "scrap metal buyers {city}",
            "metal recycling center {city}",
            "copper aluminum steel buyers {city}",
            "junk yard {city}",
            "auto salvage {city}",
            "metal scrap dealer {city}",
            "industrial metal recycling {city}",
            "scrap metal pickup {city}",
            "metal recycling services {city}",
            "scrap yard near {city}"
        ]
        
        # –ì–æ—Ä–æ–¥–∞ –¥–ª—è –≥–ª—É–±–æ–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞ (—Å—Ä–µ–¥–Ω–∏–µ –≥–æ—Ä–æ–¥–∞, –≥–¥–µ –º–µ–Ω—å—à–µ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ü–∏–∏)
        self.target_cities = [
            "Akron OH", "Toledo OH", "Dayton OH", "Youngstown OH",
            "Rochester NY", "Syracuse NY", "Albany NY", "Buffalo NY",
            "Camden NJ", "Trenton NJ", "Paterson NJ", "Newark NJ",
            "Gary IN", "Fort Wayne IN", "Evansville IN", "South Bend IN",
            "Flint MI", "Lansing MI", "Kalamazoo MI", "Battle Creek MI",
            "Shreveport LA", "Lafayette LA", "Lake Charles LA", "Monroe LA",
            "Mobile AL", "Huntsville AL", "Montgomery AL", "Tuscaloosa AL",
            "Chattanooga TN", "Knoxville TN", "Clarksville TN", "Murfreesboro TN",
            "Little Rock AR", "Fort Smith AR", "Fayetteville AR", "Pine Bluff AR",
            "Wichita KS", "Topeka KS", "Lawrence KS", "Overland Park KS",
            "Springfield MO", "Independence MO", "Columbia MO", "St. Joseph MO"
        ]
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ —Ç–µ–ª–µ—Ñ–æ–Ω–æ–≤
        self.aggressive_phone_patterns = [
            r'tel:\+?1?[-.\s]?\(?(\d{3})\)?[-.\s]?(\d{3})[-.\s]?(\d{4})',
            r'call\s*:?\s*\+?1?[-.\s]?\(?(\d{3})\)?[-.\s]?(\d{3})[-.\s]?(\d{4})',
            r'phone\s*:?\s*\+?1?[-.\s]?\(?(\d{3})\)?[-.\s]?(\d{3})[-.\s]?(\d{4})',
            r'contact\s*:?\s*\+?1?[-.\s]?\(?(\d{3})\)?[-.\s]?(\d{3})[-.\s]?(\d{4})',
            r'\+?1?[-.\s]?\(?(\d{3})\)?[-.\s]?(\d{3})[-.\s]?(\d{4})',
            r'(\d{3})[-.\s](\d{3})[-.\s](\d{4})',
            r'\((\d{3})\)\s*(\d{3})[-.\s](\d{4})',
            r'(\d{3})\.(\d{3})\.(\d{4})',
            r'(\d{10})',
            # –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è —Å–∫—Ä—ã—Ç—ã—Ö –Ω–æ–º–µ—Ä–æ–≤
            r'href="tel:([^"]+)"',
            r'data-phone[^>]*>([^<]+)',
            r'class="phone[^>]*>([^<]+)',
            r'id="phone[^>]*>([^<]+)'
        ]

    def _setup_logging(self):
        logger = logging.getLogger('ContactFocusedScraper')
        logger.setLevel(logging.INFO)
        
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
            handler.setFormatter(formatter)
            logger.addHandler(handler)
        
        return logger

    def scrape_with_contact_priority(self, target_count=200):
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥: –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–π —Å–±–æ—Ä —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤"""
        self.logger.info(f"üéØ –ö–û–ù–¢–ê–ö–¢-–§–û–ö–£–°–ò–†–û–í–ê–ù–ù–´–ô –°–ë–û–† –¥–ª—è {target_count} –±–∏–∑–Ω–µ—Å–æ–≤")
        self.logger.info(f"üìû –¶–ï–õ–¨: –º–∏–Ω–∏–º—É–º {self.MIN_CONTACT_PERCENTAGE}% —Å —Ç–µ–ª–µ—Ñ–æ–Ω–∞–º–∏")
        
        # –§–∞–∑–∞ 1: –ë–∞–∑–æ–≤—ã–π —Å–±–æ—Ä –∏–∑ OSM + —É—Å–∏–ª–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤
        basic_businesses = self._enhanced_osm_collection(target_count // 2)
        
        # –§–∞–∑–∞ 2: Google –≥–ª—É–±–∏–Ω–Ω—ã–π –ø–æ–∏—Å–∫ –¥–ª—è –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏—Ö –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤
        google_businesses = self._google_deep_search(target_count // 2)
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –∏ —É–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
        all_businesses = self._merge_and_dedupe(basic_businesses + google_businesses)
        
        # –§–∞–∑–∞ 3: –ê–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤
        final_businesses = self._aggressive_contact_extraction(all_businesses)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤
        contact_percentage = self._calculate_contact_percentage(final_businesses)
        self.logger.info(f"üìä –†–ï–ó–£–õ–¨–¢–ê–¢: {contact_percentage:.1f}% –±–∏–∑–Ω–µ—Å–æ–≤ —Å —Ç–µ–ª–µ—Ñ–æ–Ω–∞–º–∏")
        
        if contact_percentage < self.MIN_CONTACT_PERCENTAGE:
            self.logger.warning(f"‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤! –ó–∞–ø—É—Å–∫–∞—é –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –ø–æ–∏—Å–∫...")
            additional_businesses = self._emergency_contact_search(target_count)
            final_businesses.extend(additional_businesses)
        
        self.results = final_businesses[:target_count]
        return self.results

    def _enhanced_osm_collection(self, target_count):
        """–£–ª—É—á—à–µ–Ω–Ω—ã–π —Å–±–æ—Ä OSM —Å —Ñ–æ–∫—É—Å–æ–º –Ω–∞ –∫–æ–Ω—Ç–∞–∫—Ç—ã"""
        self.logger.info(f"üìç OSM —Å–±–æ—Ä —Å –∫–æ–Ω—Ç–∞–∫—Ç-—Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π –¥–ª—è {target_count} –±–∏–∑–Ω–µ—Å–æ–≤")
        
        results = []
        base_url = "https://overpass-api.de/api/interpreter"
        
        # –ú–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å —Å —Ñ–æ–∫—É—Å–æ–º –Ω–∞ –∫–æ–Ω—Ç–∞–∫—Ç—ã
        query = """
        [out:json][timeout:45];
        (
          node["shop"="scrap_yard"]["phone"](bbox);
          node["amenity"="recycling"]["phone"](bbox);
          node["industrial"="scrap_yard"]["phone"](bbox);
          node["shop"="scrap_yard"]["contact:phone"](bbox);
          node["amenity"="recycling"]["contact:phone"](bbox);
          node["shop"="scrap_yard"](bbox);
          node["amenity"="recycling"](bbox);
          node["industrial"="scrap_yard"](bbox);
          node[name~"scrap|metal|recycl|salvage"][phone](bbox);
          way[name~"scrap|metal|recycl|salvage"][phone](bbox);
        );
        out center meta tags;
        """
        
        # –ö–æ–Ω—Ü–µ–Ω—Ç—Ä–∏—Ä—É–µ–º—Å—è –Ω–∞ –∏–Ω–¥—É—Å—Ç—Ä–∏–∞–ª—å–Ω—ã—Ö –æ–±–ª–∞—Å—Ç—è—Ö
        industrial_bboxes = [
            "41.49,-87.92,42.02,-87.52",  # Chicago Industrial
            "29.52,-95.67,30.11,-95.07",  # Houston Ship Channel
            "33.93,-84.67,34.25,-84.13",  # Atlanta Industrial
            "39.72,-75.28,40.14,-74.95",  # Philadelphia Industrial
            "42.23,-83.29,42.45,-82.91",  # Detroit Industrial
            "40.40,-80.15,40.60,-79.85",  # Pittsburgh Steel Area
            "33.65,-87.05,33.85,-86.65",  # Birmingham Steel
        ]
        
        for i, bbox in enumerate(industrial_bboxes):
            try:
                self.logger.info(f"üè≠ –ü–æ–∏—Å–∫ –≤ –∏–Ω–¥—É—Å—Ç—Ä–∏–∞–ª—å–Ω–æ–π –∑–æ–Ω–µ {i+1}/{len(industrial_bboxes)}")
                bbox_query = query.replace("(bbox)", f"({bbox})")
                
                response = self._make_safe_request(base_url, data=bbox_query, method='POST')
                if response and response.status_code == 200:
                    data = response.json()
                    businesses = self._parse_osm_with_contact_priority(data)
                    results.extend(businesses)
                    
                    contacts_found = sum(1 for b in businesses if b.get('phone'))
                    self.logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(businesses)} –±–∏–∑–Ω–µ—Å–æ–≤, {contacts_found} —Å —Ç–µ–ª–µ—Ñ–æ–Ω–∞–º–∏")
                
                time.sleep(random.uniform(3, 6))
                
                if len(results) >= target_count:
                    break
                    
            except Exception as e:
                self.logger.warning(f"‚ùå OSM –æ—à–∏–±–∫–∞ –≤ –∑–æ–Ω–µ {i+1}: {e}")
                continue
        
        return results

    def _parse_osm_with_contact_priority(self, data):
        """–ü–∞—Ä—Å–∏–Ω–≥ OSM —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤"""
        businesses = []
        
        try:
            if 'elements' in data:
                for element in data['elements']:
                    tags = element.get('tags', {})
                    
                    # –ü–æ–ª—É—á–∞–µ–º –∏–º—è
                    name = (tags.get('name') or 
                           tags.get('operator') or 
                           tags.get('brand', ''))
                    
                    if not name or len(name.strip()) < 3:
                        continue
                    
                    # –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã
                    lat = element.get('lat')
                    lon = element.get('lon')
                    
                    if not lat and 'center' in element:
                        lat = element['center']['lat']
                        lon = element['center']['lon']
                    
                    # –ê–ì–†–ï–°–°–ò–í–ù–´–ô –ø–æ–∏—Å–∫ —Ç–µ–ª–µ—Ñ–æ–Ω–∞
                    phone = self._extract_phone_aggressive(tags)
                    
                    business = {
                        'name': name.strip(),
                        'address': self._build_address(tags),
                        'city': tags.get('addr:city', ''),
                        'state': tags.get('addr:state', ''),
                        'zip_code': tags.get('addr:postcode', ''),
                        'phone': phone,
                        'website': tags.get('website', tags.get('contact:website', '')),
                        'email': tags.get('email', tags.get('contact:email', '')),
                        'latitude': float(lat) if lat else None,
                        'longitude': float(lon) if lon else None,
                        'source': 'OSM_Contact_Priority',
                        'osm_id': str(element.get('id', '')),
                        'scraped_at': datetime.now().isoformat(),
                        'has_contact': bool(phone)  # –ú–∞—Ä–∫–µ—Ä –Ω–∞–ª–∏—á–∏—è –∫–æ–Ω—Ç–∞–∫—Ç–∞
                    }
                    
                    businesses.append(business)
                        
        except Exception as e:
            self.logger.error(f"OSM –ø–∞—Ä—Å–∏–Ω–≥ –æ—à–∏–±–∫–∞: {e}")
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º: —Å–Ω–∞—á–∞–ª–∞ —Å –∫–æ–Ω—Ç–∞–∫—Ç–∞–º–∏
        businesses.sort(key=lambda x: x.get('has_contact', False), reverse=True)
        return businesses

    def _extract_phone_aggressive(self, tags):
        """–ê–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–ª–µ—Ñ–æ–Ω–∞ –∏–∑ –≤—Å–µ—Ö –≤–æ–∑–º–æ–∂–Ω—ã—Ö –ø–æ–ª–µ–π"""
        phone_fields = [
            'phone', 'contact:phone', 'telephone', 'contact:telephone',
            'phone:mobile', 'contact:mobile', 'fax', 'contact:fax'
        ]
        
        for field in phone_fields:
            if field in tags and tags[field]:
                phone = self._clean_phone(tags[field])
                if phone:
                    return phone
        
        return ""

    def _google_deep_search(self, target_count):
        """Google –ø–æ–∏—Å–∫ –∫–æ–º–ø–∞–Ω–∏–π —Å –Ω–∏–∑–∫–∏–º–∏ –ø–æ–∑–∏—Ü–∏—è–º–∏"""
        self.logger.info(f"üîç Google –≥–ª—É–±–∏–Ω–Ω—ã–π –ø–æ–∏—Å–∫ –¥–ª—è {target_count} –∫–æ–º–ø–∞–Ω–∏–π")
        
        results = []
        
        # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –≤–µ–±-–¥—Ä–∞–π–≤–µ—Ä –¥–ª—è Google
        driver = self._setup_webdriver()
        
        try:
            for city in self.target_cities[:20]:  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
                if len(results) >= target_count:
                    break
                
                for query_template in self.deep_search_queries[:5]:  # –¢–æ–ø-5 –∑–∞–ø—Ä–æ—Å–æ–≤
                    query = query_template.format(city=city)
                    
                    self.logger.info(f"üîé Google –ø–æ–∏—Å–∫: {query}")
                    
                    # –°–æ–±–∏—Ä–∞–µ–º —Å—Å—ã–ª–∫–∏ —Å –≥–ª—É–±–æ–∫–∏—Ö —Å—Ç—Ä–∞–Ω–∏—Ü Google
                    deep_links = self._scrape_google_deep_results(driver, query)
                    
                    # –ü–∞—Ä—Å–∏–º –∫–∞–∂–¥—É—é —Å—Å—ã–ª–∫—É –¥–ª—è –ø–æ–∏—Å–∫–∞ –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤
                    for link in deep_links:
                        try:
                            business_data = self._scrape_business_for_contacts(link, city)
                            if business_data and business_data.get('phone'):
                                results.append(business_data)
                                
                            if len(results) >= target_count:
                                break
                                
                        except Exception as e:
                            self.logger.debug(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ {link}: {e}")
                            continue
                    
                    # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
                    time.sleep(random.uniform(10, 20))
                    
                    if len(results) >= target_count:
                        break
        
        finally:
            driver.quit()
        
        self.logger.info(f"‚úÖ Google –ø–æ–∏—Å–∫ –∑–∞–≤–µ—Ä—à–µ–Ω: {len(results)} –±–∏–∑–Ω–µ—Å–æ–≤ —Å –∫–æ–Ω—Ç–∞–∫—Ç–∞–º–∏")
        return results

    def _setup_webdriver(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –≤–µ–±-–¥—Ä–∞–π–≤–µ—Ä–∞ –¥–ª—è Google"""
        options = Options()
        options.add_argument('--headless')
        options.add_argument('--no-sandbox')
        options.add_argument('--disable-dev-shm-usage')
        options.add_argument('--disable-blink-features=AutomationControlled')
        options.add_experimental_option("excludeSwitches", ["enable-automation"])
        options.add_experimental_option('useAutomationExtension', False)
        options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36")
        
        driver = webdriver.Chrome(options=options)
        driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
        
        return driver

    def _scrape_google_deep_results(self, driver, query, max_pages=5):
        """–ü–∞—Ä—Å–∏–º –≥–ª—É–±–æ–∫–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã Google (—Å—Ç—Ä–∞–Ω–∏—Ü—ã 2-5)"""
        deep_links = []
        
        try:
            # –§–æ—Ä–º–∏—Ä—É–µ–º URL –ø–æ–∏—Å–∫–∞
            search_url = f"https://www.google.com/search?q={quote_plus(query)}"
            driver.get(search_url)
            
            # –ñ–¥–µ–º –∑–∞–≥—Ä—É–∑–∫–∏
            WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, "div.g"))
            )
            
            # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –Ω–∞ –≥–ª—É–±–æ–∫–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã (2-5) –≥–¥–µ –º–µ–Ω—å—à–µ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ü–∏–∏
            for page in range(2, max_pages + 1):
                try:
                    # –ù–∞—Ö–æ–¥–∏–º —Å—Å—ã–ª–∫—É –Ω–∞ —Å–ª–µ–¥—É—é—â—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É
                    next_button = driver.find_element(By.CSS_SELECTOR, "a[aria-label*='Page']")
                    driver.execute_script("arguments[0].click();", next_button)
                    
                    time.sleep(random.uniform(3, 7))
                    
                    # –°–æ–±–∏—Ä–∞–µ–º —Å—Å—ã–ª–∫–∏ —Å —ç—Ç–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
                    page_links = self._extract_google_page_links(driver)
                    deep_links.extend(page_links)
                    
                    self.logger.info(f"üìÑ –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page}: —Å–æ–±—Ä–∞–Ω–æ {len(page_links)} —Å—Å—ã–ª–æ–∫")
                    
                except Exception as e:
                    self.logger.debug(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–µ—Ä–µ–π—Ç–∏ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É {page}: {e}")
                    break
        
        except Exception as e:
            self.logger.warning(f"Google –ø–æ–∏—Å–∫ –æ—à–∏–±–∫–∞: {e}")
        
        return deep_links[:50]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ

    def _extract_google_page_links(self, driver):
        """–ò–∑–≤–ª–µ–∫–∞–µ–º —Å—Å—ã–ª–∫–∏ —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã Google –∏—Å–ø–æ–ª—å–∑—É—è –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π JS"""
        try:
            # –ê–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ —Å–∫—Ä–∏–ø—Ç–∞
            js_script = """
            var links = [];
            var elements = document.querySelectorAll('div.g a[href]');
            elements.forEach(function(element) {
                var href = element.getAttribute('href');
                var title = element.querySelector('h3');
                if (href && href.startsWith('http') && title) {
                    links.push({
                        url: href,
                        title: title.innerText,
                        description: ''
                    });
                }
            });
            return links;
            """
            
            links_data = driver.execute_script(js_script)
            return [link['url'] for link in links_data if self._is_relevant_business_link(link['url'])]
            
        except Exception as e:
            self.logger.debug(f"JS –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—Å—ã–ª–æ–∫ –æ—à–∏–±–∫–∞: {e}")
            return []

    def _is_relevant_business_link(self, url):
        """–ü—Ä–æ–≤–µ—Ä—è–µ–º, —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–∞ –ª–∏ —Å—Å—ã–ª–∫–∞ –¥–ª—è –±–∏–∑–Ω–µ—Å–∞"""
        skip_domains = [
            'google.com', 'facebook.com', 'youtube.com', 'twitter.com',
            'yelp.com', 'yellowpages.com', 'wikipedia.org', 'maps.google.com'
        ]
        
        url_lower = url.lower()
        return not any(domain in url_lower for domain in skip_domains)

    def _scrape_business_for_contacts(self, url, city):
        """–ü–∞—Ä—Å–∏–º –±–∏–∑–Ω–µ—Å-—Å–∞–π—Ç —Å —Ñ–æ–∫—É—Å–æ–º –Ω–∞ –∫–æ–Ω—Ç–∞–∫—Ç—ã"""
        try:
            response = self._make_safe_request(url, timeout=15)
            if not response or response.status_code != 200:
                return None
            
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # –ê–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫ —Ç–µ–ª–µ—Ñ–æ–Ω–æ–≤
            phone = self._extract_phone_from_page(soup, response.text)
            
            if not phone:  # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ —Ç–µ–ª–µ—Ñ–æ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                return None
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –±–∞–∑–æ–≤—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
            business = {
                'name': self._extract_business_name(soup),
                'phone': phone,
                'email': self._extract_email_from_page(soup, response.text),
                'website': url,
                'city': city.split()[0],  # –ò–∑–≤–ª–µ–∫–∞–µ–º –≥–æ—Ä–æ–¥
                'state': city.split()[-1] if len(city.split()) > 1 else '',
                'address': self._extract_address_from_page(soup),
                'source': 'Google_Deep_Search',
                'scraped_at': datetime.now().isoformat(),
                'has_contact': True
            }
            
            return business
            
        except Exception as e:
            self.logger.debug(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ {url}: {e}")
            return None

    def _extract_phone_from_page(self, soup, page_text):
        """–ê–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–ª–µ—Ñ–æ–Ω–∞ —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
        # –ò—â–µ–º –≤ HTML —Ç–µ–≥–∞—Ö
        phone_selectors = [
            'a[href^="tel:"]', '[data-phone]', '.phone', '#phone',
            '.contact-phone', '.telephone', '.phone-number',
            '.contact .phone', '.header-phone', '.footer-phone'
        ]
        
        for selector in phone_selectors:
            elements = soup.select(selector)
            for element in elements:
                if selector.startswith('a[href^="tel:"]'):
                    phone_text = element.get('href', '').replace('tel:', '')
                else:
                    phone_text = element.get('data-phone') or element.get_text()
                
                phone = self._clean_phone(phone_text)
                if phone:
                    return phone
        
        # –ò—â–µ–º –≤ —Ç–µ–∫—Å—Ç–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º
        for pattern in self.aggressive_phone_patterns:
            matches = re.findall(pattern, page_text, re.IGNORECASE)
            for match in matches:
                if isinstance(match, tuple):
                    # –ì—Ä—É–ø–ø—ã –∑–∞—Ö–≤–∞—Ç–∞: (area, first, last)
                    phone = f"({match[0]}) {match[1]}-{match[2]}"
                else:
                    phone = str(match)
                
                cleaned = self._clean_phone(phone)
                if cleaned:
                    return cleaned
        
        return ""

    def _extract_email_from_page(self, soup, page_text):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ email —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
        # Email –ø–∞—Ç—Ç–µ—Ä–Ω
        email_pattern = r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'
        
        # –ò—â–µ–º –≤ —Ç–µ–∫—Å—Ç–µ
        emails = re.findall(email_pattern, page_text)
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º –Ω–µ–∂–µ–ª–∞—Ç–µ–ª—å–Ω—ã–µ email'—ã
        valid_emails = []
        skip_domains = ['example.com', 'test.com', 'placeholder.com', 'google.com']
        
        for email in emails:
            if not any(domain in email.lower() for domain in skip_domains):
                valid_emails.append(email)
        
        return valid_emails[0] if valid_emails else ""

    def _extract_business_name(self, soup):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è –±–∏–∑–Ω–µ—Å–∞"""
        name_selectors = [
            'h1', 'title', '.business-name', '.company-name',
            '.site-title', '.logo-text', '.header h1'
        ]
        
        for selector in name_selectors:
            element = soup.select_one(selector)
            if element:
                name = element.get_text().strip()
                if name and len(name) > 3:
                    return name[:100]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
        
        return "Unknown Business"

    def _extract_address_from_page(self, soup):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∞–¥—Ä–µ—Å–∞ —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
        address_selectors = [
            '.address', '.location', '.contact-address',
            '[itemtype*="PostalAddress"]', '.street-address'
        ]
        
        for selector in address_selectors:
            element = soup.select_one(selector)
            if element:
                address = element.get_text().strip()
                if address and any(word in address.lower() for word in ['street', 'ave', 'road', 'drive', 'blvd']):
                    return address[:200]
        
        return ""

    def _aggressive_contact_extraction(self, businesses):
        """–ê–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤ –¥–ª—è –±–∏–∑–Ω–µ—Å–æ–≤ –±–µ–∑ —Ç–µ–ª–µ—Ñ–æ–Ω–æ–≤"""
        self.logger.info(f"üìû –ê–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫ –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤ –¥–ª—è {len(businesses)} –±–∏–∑–Ω–µ—Å–æ–≤")
        
        enhanced_businesses = []
        
        for business in businesses:
            if business.get('phone'):  # –£–∂–µ –µ—Å—Ç—å —Ç–µ–ª–µ—Ñ–æ–Ω
                enhanced_businesses.append(business)
                continue
            
            # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –∫–æ–Ω—Ç–∞–∫—Ç—ã —á–µ—Ä–µ–∑ —Ä–∞–∑–Ω—ã–µ –º–µ—Ç–æ–¥—ã
            enhanced = business.copy()
            
            # –ú–µ—Ç–æ–¥ 1: –ü–æ–∏—Å–∫ —á–µ—Ä–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏–µ + –≥–æ—Ä–æ–¥ –≤ Google
            if not enhanced.get('phone'):
                phone = self._search_phone_by_name_city(enhanced)
                if phone:
                    enhanced['phone'] = phone
                    enhanced['phone_source'] = 'google_search'
            
            # –ú–µ—Ç–æ–¥ 2: –ï—Å–ª–∏ –µ—Å—Ç—å —Å–∞–π—Ç, –ø–∞—Ä—Å–∏–º –µ–≥–æ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ
            if not enhanced.get('phone') and enhanced.get('website'):
                phone = self._deep_scrape_website_for_phone(enhanced['website'])
                if phone:
                    enhanced['phone'] = phone
                    enhanced['phone_source'] = 'website_deep'
            
            # –ú–µ—Ç–æ–¥ 3: –ü–æ–∏—Å–∫ –≤ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∞—Ö
            if not enhanced.get('phone'):
                phone = self._search_business_directories(enhanced)
                if phone:
                    enhanced['phone'] = phone
                    enhanced['phone_source'] = 'directories'
            
            enhanced['has_contact'] = bool(enhanced.get('phone'))
            enhanced_businesses.append(enhanced)
        
        return enhanced_businesses

    def _search_phone_by_name_city(self, business):
        """–ü–æ–∏—Å–∫ —Ç–µ–ª–µ—Ñ–æ–Ω–∞ —á–µ—Ä–µ–∑ Google –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é + –≥–æ—Ä–æ–¥"""
        try:
            name = business.get('name', '')
            city = business.get('city', '')
            state = business.get('state', '')
            
            if not name:
                return ""
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
            query = f'"{name}" {city} {state} phone contact scrap metal'
            search_url = f"https://www.google.com/search?q={quote_plus(query)}"
            
            response = self._make_safe_request(search_url)
            if response and response.status_code == 200:
                # –ò—â–µ–º —Ç–µ–ª–µ—Ñ–æ–Ω—ã –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö –ø–æ–∏—Å–∫–∞
                for pattern in self.aggressive_phone_patterns:
                    matches = re.findall(pattern, response.text, re.IGNORECASE)
                    for match in matches:
                        phone = self._format_phone_match(match)
                        if phone:
                            return phone
            
        except Exception as e:
            self.logger.debug(f"Google phone search error: {e}")
        
        return ""

    def _deep_scrape_website_for_phone(self, website):
        """–ì–ª—É–±–æ–∫–∏–π –ø–∞—Ä—Å–∏–Ω–≥ —Å–∞–π—Ç–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ç–µ–ª–µ—Ñ–æ–Ω–∞"""
        try:
            # –ü–∞—Ä—Å–∏–º –≥–ª–∞–≤–Ω—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É
            response = self._make_safe_request(website, timeout=10)
            if not response or response.status_code != 200:
                return ""
            
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # –ò—â–µ–º –Ω–∞ –≥–ª–∞–≤–Ω–æ–π
            phone = self._extract_phone_from_page(soup, response.text)
            if phone:
                return phone
            
            # –ò—â–µ–º —Å—Å—ã–ª–∫–∏ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤
            contact_links = self._find_contact_page_links(soup, website)
            
            for contact_url in contact_links:
                try:
                    contact_response = self._make_safe_request(contact_url, timeout=10)
                    if contact_response and contact_response.status_code == 200:
                        contact_soup = BeautifulSoup(contact_response.text, 'html.parser')
                        phone = self._extract_phone_from_page(contact_soup, contact_response.text)
                        if phone:
                            return phone
                except:
                    continue
            
        except Exception as e:
            self.logger.debug(f"Deep website scrape error: {e}")
        
        return ""

    def _find_contact_page_links(self, soup, base_url):
        """–ù–∞—Ö–æ–¥–∏–º —Å—Å—ã–ª–∫–∏ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤"""
        contact_keywords = ['contact', 'about', 'phone', 'call', 'reach']
        contact_links = []
        
        links = soup.find_all('a', href=True)
        for link in links:
            href = link.get('href', '')
            text = link.get_text().lower()
            
            if any(keyword in text for keyword in contact_keywords):
                full_url = urljoin(base_url, href)
                if full_url not in contact_links:
                    contact_links.append(full_url)
        
        return contact_links[:5]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ

    def _search_business_directories(self, business):
        """–ü–æ–∏—Å–∫ –≤ –±–∏–∑–Ω–µ—Å-—Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∞—Ö"""
        directories = [
            'yellowpages.com',
            'whitepages.com', 
            'superpages.com'
        ]
        
        name = business.get('name', '')
        city = business.get('city', '')
        
        if not name:
            return ""
        
        for directory in directories:
            try:
                query = f'site:{directory} "{name}" {city} phone'
                search_url = f"https://www.google.com/search?q={quote_plus(query)}"
                
                response = self._make_safe_request(search_url)
                if response and response.status_code == 200:
                    for pattern in self.aggressive_phone_patterns:
                        matches = re.findall(pattern, response.text, re.IGNORECASE)
                        for match in matches:
                            phone = self._format_phone_match(match)
                            if phone:
                                return phone
            except:
                continue
        
        return ""

    def _format_phone_match(self, match):
        """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–π —Ç–µ–ª–µ—Ñ–æ–Ω"""
        if isinstance(match, tuple):
            if len(match) == 3:
                return f"({match[0]}) {match[1]}-{match[2]}"
            else:
                return ''.join(match)
        else:
            return self._clean_phone(str(match))

    def _clean_phone(self, phone):
        """–û—á–∏—Å—Ç–∫–∞ –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–µ–ª–µ—Ñ–æ–Ω–∞"""
        if not phone:
            return ""
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–æ–ª—å–∫–æ —Ü–∏—Ñ—Ä—ã
        digits = re.sub(r'\D', '', phone)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å
        if len(digits) == 10:
            return f"({digits[:3]}) {digits[3:6]}-{digits[6:]}"
        elif len(digits) == 11 and digits[0] == '1':
            return f"({digits[1:4]}) {digits[4:7]}-{digits[7:]}"
        elif len(digits) >= 10:
            # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 10 —Ü–∏—Ñ—Ä
            last_10 = digits[-10:]
            return f"({last_10[:3]}) {last_10[3:6]}-{last_10[6:]}"
        
        return ""

    def _build_address(self, tags):
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∞–¥—Ä–µ—Å–∞ –∏–∑ OSM —Ç–µ–≥–æ–≤"""
        parts = []
        if tags.get('addr:housenumber'):
            parts.append(tags['addr:housenumber'])
        if tags.get('addr:street'):
            parts.append(tags['addr:street'])
        return ' '.join(parts) if parts else ""

    def _merge_and_dedupe(self, businesses):
        """–û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –∏ —É–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤"""
        seen = set()
        unique_businesses = []
        
        for business in businesses:
            # –°–æ–∑–¥–∞–µ–º –∫–ª—é—á –¥–ª—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏
            name = business.get('name', '').lower().strip()
            city = business.get('city', '').lower().strip()
            phone = business.get('phone', '').strip()
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ–ª–µ—Ñ–æ–Ω –∫–∞–∫ –æ—Å–Ω–æ–≤–Ω–æ–π –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä, –µ—Å–ª–∏ –µ—Å—Ç—å
            if phone:
                key = phone
            else:
                key = f"{name}_{city}"
            
            if key not in seen and name:
                seen.add(key)
                unique_businesses.append(business)
        
        return unique_businesses

    def _calculate_contact_percentage(self, businesses):
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç –±–∏–∑–Ω–µ—Å–æ–≤ —Å –∫–æ–Ω—Ç–∞–∫—Ç–∞–º–∏"""
        if not businesses:
            return 0
        
        with_contacts = sum(1 for b in businesses if b.get('phone'))
        return (with_contacts / len(businesses)) * 100

    def _emergency_contact_search(self, target_count):
        """–≠–∫—Å—Ç—Ä–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤, –µ—Å–ª–∏ –æ—Å–Ω–æ–≤–Ω–æ–π –Ω–µ –¥–∞–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞"""
        self.logger.info("üö® –≠–ö–°–¢–†–ï–ù–ù–´–ô —Ä–µ–∂–∏–º –ø–æ–∏—Å–∫–∞ –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤")
        
        emergency_results = []
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–µ –º–µ—Ç–æ–¥—ã
        emergency_queries = [
            "scrap metal phone number {city}",
            "metal recycling contact {city}",
            "junk yard phone {city}",
            "scrap dealer call {city}"
        ]
        
        for city in self.target_cities[:10]:
            for query_template in emergency_queries:
                query = query_template.format(city=city)
                
                try:
                    # –ü—Ä–æ—Å—Ç–æ–π HTTP –ø–æ–∏—Å–∫ –±–µ–∑ Selenium
                    search_url = f"https://duckduckgo.com/?q={quote_plus(query)}"
                    response = self._make_safe_request(search_url)
                    
                    if response and response.status_code == 200:
                        # –ò—â–µ–º —Ç–µ–ª–µ—Ñ–æ–Ω—ã –ø—Ä—è–º–æ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö
                        for pattern in self.aggressive_phone_patterns:
                            matches = re.findall(pattern, response.text, re.IGNORECASE)
                            for match in matches:
                                phone = self._format_phone_match(match)
                                if phone:
                                    emergency_results.append({
                                        'name': f"Emergency Contact {len(emergency_results) + 1}",
                                        'phone': phone,
                                        'city': city.split()[0],
                                        'state': city.split()[-1] if len(city.split()) > 1 else '',
                                        'source': 'Emergency_Search',
                                        'scraped_at': datetime.now().isoformat(),
                                        'has_contact': True
                                    })
                                    
                                    if len(emergency_results) >= target_count // 4:
                                        return emergency_results
                
                except Exception as e:
                    self.logger.debug(f"Emergency search error: {e}")
                    continue
                
                time.sleep(1)  # –ë—ã—Å—Ç—Ä–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞
        
        return emergency_results

    def _make_safe_request(self, url, params=None, data=None, method='GET', timeout=30, max_retries=3):
        """–ë–µ–∑–æ–ø–∞—Å–Ω—ã–π HTTP –∑–∞–ø—Ä–æ—Å"""
        for attempt in range(max_retries):
            try:
                headers = {
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
                    'Accept-Language': 'en-US,en;q=0.9',
                    'Accept-Encoding': 'gzip, deflate',
                    'Connection': 'keep-alive'
                }
                
                time.sleep(random.uniform(1, 3))
                
                if method == 'POST':
                    response = self.session.post(url, headers=headers, data=data, timeout=timeout)
                else:
                    response = self.session.get(url, headers=headers, params=params, timeout=timeout)
                
                if response.status_code == 200:
                    return response
                elif response.status_code == 429:
                    wait_time = (attempt + 1) * 10
                    self.logger.warning(f"Rate limit, –∂–¥–µ–º {wait_time}s")
                    time.sleep(wait_time)
                
            except Exception as e:
                if attempt < max_retries - 1:
                    time.sleep(random.uniform(2, 5))
        
        return None

    def export_contact_focused_results(self, output_dir="output"):
        """–≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å —Ñ–æ–∫—É—Å–æ–º –Ω–∞ –∫–æ–Ω—Ç–∞–∫—Ç—ã"""
        if not self.results:
            self.logger.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞")
            return None
        
        os.makedirs(output_dir, exist_ok=True)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤
        total_businesses = len(self.results)
        with_phones = sum(1 for b in self.results if b.get('phone'))
        with_emails = sum(1 for b in self.results if b.get('email'))
        with_websites = sum(1 for b in self.results if b.get('website'))
        
        contact_percentage = (with_phones / total_businesses) * 100 if total_businesses > 0 else 0
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º: —Å–Ω–∞—á–∞–ª–∞ —Å –∫–æ–Ω—Ç–∞–∫—Ç–∞–º–∏
        sorted_results = sorted(self.results, key=lambda x: bool(x.get('phone')), reverse=True)
        
        # –≠–∫—Å–ø–æ—Ä—Ç –≤ CSV
        df = pd.DataFrame(sorted_results)
        csv_file = os.path.join(output_dir, f"contact_focused_businesses_{timestamp}.csv")
        df.to_csv(csv_file, index=False)
        
        # –≠–∫—Å–ø–æ—Ä—Ç –≤ Excel —Å –∞–Ω–∞–ª–∏–∑–æ–º –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤
        excel_file = os.path.join(output_dir, f"contact_focused_businesses_{timestamp}.xlsx")
        with pd.ExcelWriter(excel_file, engine='openpyxl') as writer:
            # –û—Å–Ω–æ–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            df.to_excel(writer, sheet_name='All Businesses', index=False)
            
            # –¢–æ–ª—å–∫–æ —Å –∫–æ–Ω—Ç–∞–∫—Ç–∞–º–∏
            businesses_with_contacts = df[df['phone'].notna() & (df['phone'] != '')]
            if not businesses_with_contacts.empty:
                businesses_with_contacts.to_excel(writer, sheet_name='With Phone Numbers', index=False)
            
            # –ë–µ–∑ –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤ (–¥–ª—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏)
            businesses_without_contacts = df[df['phone'].isna() | (df['phone'] == '')]
            if not businesses_without_contacts.empty:
                businesses_without_contacts.to_excel(writer, sheet_name='Need Phone Numbers', index=False)
            
            # –ê–Ω–∞–ª–∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
            source_analysis = df.groupby('source').agg({
                'name': 'count',
                'phone': lambda x: x.notna().sum()
            }).reset_index()
            source_analysis.columns = ['Source', 'Total Businesses', 'With Phone']
            source_analysis['Phone Percentage'] = (source_analysis['With Phone'] / source_analysis['Total Businesses'] * 100).round(1)
            source_analysis.to_excel(writer, sheet_name='Source Analysis', index=False)
        
        # JSON —ç–∫—Å–ø–æ—Ä—Ç
        json_file = os.path.join(output_dir, f"contact_focused_businesses_{timestamp}.json")
        with open(json_file, 'w') as f:
            json.dump(sorted_results, f, indent=2, default=str)
        
        # –°–æ–∑–¥–∞–µ–º –æ—Ç—á–µ—Ç —Å –∞–∫—Ü–µ–Ω—Ç–æ–º –Ω–∞ –∫–æ–Ω—Ç–∞–∫—Ç—ã
        self._create_contact_focused_report(output_dir, timestamp, {
            'total_businesses': total_businesses,
            'with_phones': with_phones,
            'with_emails': with_emails, 
            'with_websites': with_websites,
            'contact_percentage': contact_percentage
        })
        
        self.logger.info(f"‚úÖ –ö–û–ù–¢–ê–ö–¢-–§–û–ö–£–°–ò–†–û–í–ê–ù–ù–´–ï –¥–∞–Ω–Ω—ã–µ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã:")
        self.logger.info(f"  ‚Ä¢ CSV: {csv_file}")
        self.logger.info(f"  ‚Ä¢ Excel: {excel_file}")
        self.logger.info(f"  ‚Ä¢ JSON: {json_file}")
        self.logger.info(f"üìä –†–ï–ó–£–õ–¨–¢–ê–¢: {contact_percentage:.1f}% –±–∏–∑–Ω–µ—Å–æ–≤ —Å —Ç–µ–ª–µ—Ñ–æ–Ω–∞–º–∏ ({with_phones}/{total_businesses})")
        
        return {
            'csv': csv_file,
            'excel': excel_file,
            'json': json_file,
            'total_count': total_businesses,
            'contact_percentage': contact_percentage,
            'businesses_with_phones': with_phones
        }

    def _create_contact_focused_report(self, output_dir, timestamp, stats):
        """–°–æ–∑–¥–∞–µ–º –æ—Ç—á–µ—Ç —Å —Ñ–æ–∫—É—Å–æ–º –Ω–∞ –∫–æ–Ω—Ç–∞–∫—Ç—ã"""
        report_file = os.path.join(output_dir, f"contact_focused_report_{timestamp}.txt")
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("üìû –ö–û–ù–¢–ê–ö–¢-–§–û–ö–£–°–ò–†–û–í–ê–ù–ù–´–ô –û–¢–ß–ï–¢ –ü–û SCRAP METAL –¶–ï–ù–¢–†–ê–ú\n")
            f.write("=" * 70 + "\n\n")
            f.write(f"–û—Ç—á–µ—Ç —Å–æ–∑–¥–∞–Ω: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"–ú–µ—Ç–æ–¥ —Å–±–æ—Ä–∞: –ê–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫ –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤ + Google –≥–ª—É–±–∏–Ω–Ω—ã–π\n\n")
            
            f.write("üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ö–û–ù–¢–ê–ö–¢–û–í\n")
            f.write("-" * 30 + "\n")
            f.write(f"–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–∏–∑–Ω–µ—Å–æ–≤: {stats['total_businesses']}\n")
            f.write(f"–ë–∏–∑–Ω–µ—Å—ã —Å —Ç–µ–ª–µ—Ñ–æ–Ω–∞–º–∏: {stats['with_phones']} ({stats['contact_percentage']:.1f}%)\n")
            f.write(f"–ë–∏–∑–Ω–µ—Å—ã —Å email: {stats['with_emails']}\n")
            f.write(f"–ë–∏–∑–Ω–µ—Å—ã —Å —Å–∞–π—Ç–∞–º–∏: {stats['with_websites']}\n\n")
            
            # –û—Ü–µ–Ω–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            if stats['contact_percentage'] >= self.MIN_CONTACT_PERCENTAGE:
                f.write("‚úÖ –¶–ï–õ–¨ –î–û–°–¢–ò–ì–ù–£–¢–ê: –í—ã—Å–æ–∫–∏–π –ø—Ä–æ—Ü–µ–Ω—Ç –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤!\n")
            elif stats['contact_percentage'] >= 60:
                f.write("‚ö†Ô∏è –†–ï–ó–£–õ–¨–¢–ê–¢ –ü–†–ò–ï–ú–õ–ï–ú–´–ô: –°—Ä–µ–¥–Ω–∏–π –ø—Ä–æ—Ü–µ–Ω—Ç –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤\n")
            else:
                f.write("‚ùå –†–ï–ó–£–õ–¨–¢–ê–¢ –ù–ï–£–î–û–í–õ–ï–¢–í–û–†–ò–¢–ï–õ–¨–ù–´–ô: –ù–∏–∑–∫–∏–π –ø—Ä–æ—Ü–µ–Ω—Ç –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤\n")
            
            f.write("\nüí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ü–û –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Æ\n")
            f.write("-" * 35 + "\n")
            f.write("1. –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç –∑–≤–æ–Ω–∫–∞–º –±–∏–∑–Ω–µ—Å–∞–º —Å verified –∫–æ–Ω—Ç–∞–∫—Ç–∞–º–∏\n")
            f.write("2. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å email –∫–∞–∫ —Ä–µ–∑–µ—Ä–≤–Ω—ã–π –∫–∞–Ω–∞–ª —Å–≤—è–∑–∏\n")
            f.write("3. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å —Ç–µ–ª–µ—Ñ–æ–Ω–æ–≤ –ø–µ—Ä–µ–¥ –º–∞—Å—Å–æ–≤—ã–º–∏ –∑–≤–æ–Ω–∫–∞–º–∏\n")
            f.write("4. –î–ª—è –±–∏–∑–Ω–µ—Å–æ–≤ –±–µ–∑ –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤ - –∑–∞–ø—É—Å—Ç–∏—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –ø–æ–∏—Å–∫\n")
            f.write("5. –§–æ–∫—É—Å –Ω–∞ –±–∏–∑–Ω–µ—Å—ã –∏–∑ Google –≥–ª—É–±–∏–Ω–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ (–º–µ–Ω—å—à–µ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ü–∏–∏)\n\n")
            
            f.write("üéØ –°–¢–†–ê–¢–ï–ì–ò–Ø OUTREACH\n")
            f.write("-" * 20 + "\n")
            f.write("‚Ä¢ –ì–ª—É–±–∏–Ω–Ω—ã–µ –∫–æ–º–ø–∞–Ω–∏–∏ (—Å—Ç—Ä–∞–Ω–∏—Ü—ã 2-5 Google) - –≤—ã—Å–æ–∫–∏–π –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª\n")
            f.write("‚Ä¢ –ö–æ–º–ø–∞–Ω–∏–∏ –±–µ–∑ —Å–∏–ª—å–Ω–æ–≥–æ –æ–Ω–ª–∞–π–Ω-–ø—Ä–∏—Å—É—Ç—Å—Ç–≤–∏—è –Ω—É–∂–¥–∞—é—Ç—Å—è –≤ –ø—Ä–æ–¥–≤–∏–∂–µ–Ω–∏–∏\n")
            f.write("‚Ä¢ –†–µ–≥–∏–æ–Ω–∞–ª—å–Ω—ã–µ —Ä—ã–Ω–∫–∏ –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç —Ö–æ—Ä–æ—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n")
            f.write("‚Ä¢ –ü—Ä—è–º—ã–µ –∫–æ–Ω—Ç–∞–∫—Ç—ã —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–µ–µ —á–µ–º –æ–Ω–ª–∞–π–Ω-–∑–∞—è–≤–∫–∏\n")
        
        self.logger.info(f"‚úÖ –ö–æ–Ω—Ç–∞–∫—Ç-—Ñ–æ–∫—É—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç—á–µ—Ç: {report_file}")

def main():
    print("üìû –ö–û–ù–¢–ê–ö–¢-–§–û–ö–£–°–ò–†–û–í–ê–ù–ù–´–ô –ü–ê–†–°–ï–† –¥–ª—è Scrap Metal –¶–µ–Ω—Ç—Ä–æ–≤")
    print("=" * 70)
    print("üéØ –ü–†–ò–û–†–ò–¢–ï–¢: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Å–±–æ—Ä –∫–æ–Ω—Ç–∞–∫—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
    print("üîç –°–¢–†–ê–¢–ï–ì–ò–Ø: Google –≥–ª—É–±–∏–Ω–Ω—ã–π –ø–æ–∏—Å–∫ –∫–æ–º–ø–∞–Ω–∏–π —Å –Ω–∏–∑–∫–∏–º–∏ –ø–æ–∑–∏—Ü–∏—è–º–∏")
    print("üìä –¶–ï–õ–¨: –ú–∏–Ω–∏–º—É–º 80% –±–∏–∑–Ω–µ—Å–æ–≤ —Å —Ç–µ–ª–µ—Ñ–æ–Ω–∞–º–∏")
    
    scraper = ContactFocusedScraper()
    
    try:
        target_count = int(input("\n–í–≤–µ–¥–∏—Ç–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–∏–∑–Ω–µ—Å–æ–≤ –¥–ª—è —Å–±–æ—Ä–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 200): ") or "200")
        
        print(f"\nüöÄ –ó–∞–ø—É—Å–∫ –ö–û–ù–¢–ê–ö–¢-–§–û–ö–£–°–ò–†–û–í–ê–ù–ù–û–ì–û —Å–±–æ—Ä–∞ –¥–ª—è {target_count} –±–∏–∑–Ω–µ—Å–æ–≤...")
        print("–ü—Ä–æ—Ü–µ—Å—Å –≤–∫–ª—é—á–∞–µ—Ç:")
        print("1. üìç OSM —Å–±–æ—Ä —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π –ø–æ –∫–æ–Ω—Ç–∞–∫—Ç–∞–º")
        print("2. üîç Google –≥–ª—É–±–∏–Ω–Ω—ã–π –ø–æ–∏—Å–∫ (—Å—Ç—Ä–∞–Ω–∏—Ü—ã 2-5)")
        print("3. üìû –ê–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–ª–µ—Ñ–æ–Ω–æ–≤")
        print("4. üö® –≠–∫—Å—Ç—Ä–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ –ø—Ä–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤")
        print("\n–≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å 30-60 –º–∏–Ω—É—Ç –¥–ª—è –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞...")
        
        results = scraper.scrape_with_contact_priority(target_count)
        
        if results:
            contact_stats = scraper._calculate_contact_percentage(results)
            print(f"\n‚úÖ –°–±–æ—Ä –∑–∞–≤–µ—Ä—à–µ–Ω: {len(results)} –±–∏–∑–Ω–µ—Å–æ–≤")
            print(f"üìû –ö–æ–Ω—Ç–∞–∫—Ç—ã: {contact_stats:.1f}% –±–∏–∑–Ω–µ—Å–æ–≤ —Å —Ç–µ–ª–µ—Ñ–æ–Ω–∞–º–∏")
            
            export_info = scraper.export_contact_focused_results()
            if export_info:
                print(f"\nüìÅ –§–∞–π–ª—ã —Å–æ–∑–¥–∞–Ω—ã:")
                print(f"  ‚Ä¢ CSV: {export_info['csv']}")
                print(f"  ‚Ä¢ Excel: {export_info['excel']}")
                print(f"  ‚Ä¢ JSON: {export_info['json']}")
                print(f"\nüìä –ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
                print(f"  ‚Ä¢ –í—Å–µ–≥–æ –±–∏–∑–Ω–µ—Å–æ–≤: {export_info['total_count']}")
                print(f"  ‚Ä¢ –° —Ç–µ–ª–µ—Ñ–æ–Ω–∞–º–∏: {export_info['businesses_with_phones']}")
                print(f"  ‚Ä¢ –ü—Ä–æ—Ü–µ–Ω—Ç –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤: {export_info['contact_percentage']:.1f}%")
                
                if export_info['contact_percentage'] >= scraper.MIN_CONTACT_PERCENTAGE:
                    print("\nüéâ –û–¢–õ–ò–ß–ù–û! –¶–µ–ª—å –ø–æ –∫–æ–Ω—Ç–∞–∫—Ç–∞–º –¥–æ—Å—Ç–∏–≥–Ω—É—Ç–∞!")
                else:
                    print(f"\n‚ö†Ô∏è –¶–µ–ª—å {scraper.MIN_CONTACT_PERCENTAGE}% –Ω–µ –¥–æ—Å—Ç–∏–≥–Ω—É—Ç–∞. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π —Å–±–æ—Ä.")
            else:
                print("‚ùå –û—à–∏–±–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞")
        else:
            print("‚ùå –î–∞–Ω–Ω—ã–µ –Ω–µ —Å–æ–±—Ä–∞–Ω—ã")
            
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è –ü—Ä–æ—Ü–µ—Å—Å –ø—Ä–µ—Ä–≤–∞–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")

if __name__ == "__main__":
    main() 
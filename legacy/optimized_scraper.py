#!/usr/bin/env python3
"""
–û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–´–ô –ü–ê–†–°–ï–† - –ë—ã—Å—Ç—Ä—ã–π —Å–±–æ—Ä –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤ –¥–ª—è scrap metal —Ü–µ–Ω—Ç—Ä–æ–≤
–ü–†–ò–û–†–ò–¢–ï–¢: –¢–ï–õ–ï–§–û–ù–´ –ø—Ä–µ–≤—ã—à–µ –≤—Å–µ–≥–æ!
–°–¢–†–ê–¢–ï–ì–ò–Ø: OSM + –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫ —Ç–µ–ª–µ—Ñ–æ–Ω–æ–≤ + –ø–æ–ª—É–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π Google
"""

import os
import json
import time
import random
import logging
import requests
from bs4 import BeautifulSoup
from datetime import datetime
import pandas as pd
from urllib.parse import quote_plus, urljoin
import re
from concurrent.futures import ThreadPoolExecutor, as_completed

class OptimizedScraper:
    def __init__(self):
        self.session = requests.Session()
        self.results = []
        self.logger = self._setup_logging()
        
        # –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û: –º–∏–Ω–∏–º—É–º —Ç–µ–ª–µ—Ñ–æ–Ω–æ–≤
        self.MIN_PHONES_PERCENTAGE = 80  # –¶–µ–ª—å: 80% —Å —Ç–µ–ª–µ—Ñ–æ–Ω–∞–º–∏
        
        # –ü—Ä–æ—Å—Ç—ã–µ –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã —Ç–µ–ª–µ—Ñ–æ–Ω–æ–≤
        self.phone_patterns = [
            re.compile(r'(\d{3})[^\d]*(\d{3})[^\d]*(\d{4})'),  # –û—Å–Ω–æ–≤–Ω–æ–π –ø–∞—Ç—Ç–µ—Ä–Ω
            re.compile(r'tel:[\s]*\+?1?[\s]*(\d{3})[\s]*(\d{3})[\s]*(\d{4})'),  # tel: —Å—Å—ã–ª–∫–∏
            re.compile(r'phone[\s]*:[\s]*(\d{3})[\s]*[^\d]*(\d{3})[\s]*[^\d]*(\d{4})'),  # phone:
            re.compile(r'call[\s]*:?[\s]*(\d{3})[\s]*[^\d]*(\d{3})[\s]*[^\d]*(\d{4})')   # call:
        ]
        
        # JavaScript —Å–∫—Ä–∏–ø—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (—É–ª—É—á—à–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)
        self.google_js_script = """
// –£–õ–£–ß–®–ï–ù–ù–´–ô GOOGLE –ü–ê–†–°–ï–† (–æ—Å–Ω–æ–≤–∞–Ω –Ω–∞ —Å–∫—Ä–∏–ø—Ç–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è)
javascript:!(function(){
    console.log('üîç –ó–∞–ø—É—Å–∫ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è Google —Å—Å—ã–ª–æ–∫...');
    window.scrollTo(0, document.body.scrollHeight);
    
    var win = window.open('', 'ScrapMetalLinks', 'width=1000,height=800,scrollbars=yes');
    win.document.write('<html><head><title>Scrap Metal Links</title></head><body>');
    win.document.write('<h2>üìû –ù–∞–π–¥–µ–Ω–Ω—ã–µ scrap metal –∫–æ–º–ø–∞–Ω–∏–∏</h2>');
    win.document.write('<p>–í—Ä–µ–º—è: ' + new Date().toLocaleString() + '</p>');
    
    var results = [];
    var processed = new Set();
    
    // –ò—â–µ–º –≤—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã Google
    [].forEach.call(document.getElementsByClassName('MjjYud'), function(item, index) {
        var link = item.querySelector('a');
        var href = link ? (link.getAttribute('data-href') || link.getAttribute('href')) : null;
        var title = link ? link.querySelector('h3') : null;
        var desc = item.querySelector('.VwiC3b') || item.querySelector('.s3v9rd');
        
        if (href && title && !processed.has(href)) {
            processed.add(href);
            var titleText = title.innerText || title.textContent || '';
            var descText = desc ? (desc.innerText || desc.textContent || '') : '';
            
            // –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –¥–ª—è scrap metal
            var text = (titleText + ' ' + descText).toLowerCase();
            var isRelevant = false;
            var keywords = ['scrap', 'metal', 'recycling', 'salvage', 'junk', 'steel', 'copper', 'aluminum'];
            
            for (var i = 0; i < keywords.length; i++) {
                if (text.indexOf(keywords[i]) !== -1) {
                    isRelevant = true;
                    break;
                }
            }
            
            if (isRelevant && href.indexOf('http') === 0) {
                results.push({
                    url: href,
                    title: titleText.substring(0, 100),
                    description: descText.substring(0, 200),
                    position: index + 1
                });
                
                // –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –≤ –æ–∫–Ω–µ
                win.document.write('<div style="margin:10px; padding:10px; border:1px solid #ccc;">');
                win.document.write('<strong>' + (index + 1) + '. ' + titleText + '</strong><br>');
                win.document.write('<a href="' + href + '" target="_blank">' + href + '</a><br>');
                win.document.write('<small>' + descText.substring(0, 150) + '</small>');
                win.document.write('</div>');
            }
        }
    });
    
    // JSON –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞
    win.document.write('<hr><h3>JSON –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ø–∞—Ä—Å–µ—Ä–∞:</h3>');
    win.document.write('<textarea rows="15" cols="100" onclick="this.select()">' + 
                      JSON.stringify(results, null, 2) + '</textarea>');
    win.document.write('<p><strong>–ù–∞–π–¥–µ–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Å—Å—ã–ª–æ–∫: ' + results.length + '</strong></p>');
    win.document.write('<p>–°–∫–æ–ø–∏—Ä—É–π—Ç–µ JSON –∏ —Å–æ—Ö—Ä–∞–Ω–∏—Ç–µ –≤ —Ñ–∞–π–ª google_links.json</p>');
    win.document.write('</body></html>');
    
    console.log('‚úÖ –ù–∞–π–¥–µ–Ω–æ —Å—Å—ã–ª–æ–∫:', results.length);
    return results;
})();
        """

    def _setup_logging(self):
        logger = logging.getLogger('OptimizedScraper')
        logger.setLevel(logging.INFO)
        
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
            handler.setFormatter(formatter)
            logger.addHandler(handler)
        
        return logger

    def collect_with_contact_priority(self, target_count=100):
        """–ë—ã—Å—Ç—Ä—ã–π —Å–±–æ—Ä —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤"""
        self.logger.info(f"‚ö° –ë–´–°–¢–†–´–ô –°–ë–û–† –¥–ª—è {target_count} –±–∏–∑–Ω–µ—Å–æ–≤")
        self.logger.info(f"üéØ –¶–ï–õ–¨: –º–∏–Ω–∏–º—É–º {self.MIN_PHONES_PERCENTAGE}% —Å —Ç–µ–ª–µ—Ñ–æ–Ω–∞–º–∏")
        
        # –≠—Ç–∞–ø 1: –ë—ã—Å—Ç—Ä—ã–π —Å–±–æ—Ä –∏–∑ OSM
        osm_businesses = self._fast_osm_collection(target_count)
        self.logger.info(f"üìç OSM: {len(osm_businesses)} –±–∏–∑–Ω–µ—Å–æ–≤")
        
        # –≠—Ç–∞–ø 2: –ê–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫ —Ç–µ–ª–µ—Ñ–æ–Ω–æ–≤ –¥–ª—è –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –±–∏–∑–Ω–µ—Å–æ–≤
        enhanced_businesses = self._aggressive_phone_mining(osm_businesses)
        
        # –≠—Ç–∞–ø 3: –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç —Å —Ç–µ–ª–µ—Ñ–æ–Ω–∞–º–∏
        phone_percentage = self._calculate_phone_percentage(enhanced_businesses)
        self.logger.info(f"üìû –†–µ–∑—É–ª—å—Ç–∞—Ç: {phone_percentage:.1f}% —Å —Ç–µ–ª–µ—Ñ–æ–Ω–∞–º–∏")
        
        # –≠—Ç–∞–ø 4: –ï—Å–ª–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ, –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –¥–ª—è Google
        if phone_percentage < self.MIN_PHONES_PERCENTAGE:
            self._show_google_instructions()
            google_file = "google_links.json"
            if os.path.exists(google_file):
                self.logger.info(f"üìÇ –ù–∞–π–¥–µ–Ω —Ñ–∞–π–ª {google_file}, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º...")
                google_businesses = self._process_google_links(google_file)
                enhanced_businesses.extend(google_businesses)
        
        self.results = enhanced_businesses[:target_count]
        final_percentage = self._calculate_phone_percentage(self.results)
        self.logger.info(f"‚úÖ –ò–¢–û–ì–û: {len(self.results)} –±–∏–∑–Ω–µ—Å–æ–≤, {final_percentage:.1f}% —Å —Ç–µ–ª–µ—Ñ–æ–Ω–∞–º–∏")
        
        return self.results

    def _fast_osm_collection(self, target_count):
        """–ë—ã—Å—Ç—Ä—ã–π —Å–±–æ—Ä –∏–∑ OSM –±–µ–∑ –ª–∏—à–Ω–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤"""
        businesses = []
        
        # –°–æ—Å—Ä–µ–¥–æ—Ç–∞—á–∏–≤–∞–µ–º—Å—è –Ω–∞ —Å–∞–º—ã—Ö –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω—ã—Ö —Ä–µ–≥–∏–æ–Ω–∞—Ö
        productive_bboxes = [
            "42.23,-83.29,42.45,-82.91",  # Detroit (–º–Ω–æ–≥–æ –º–µ—Ç–∞–ª–ª—É—Ä–≥–∏–∏)
            "41.49,-87.92,42.02,-87.52",  # Chicago 
            "40.60,-74.30,40.90,-73.90",  # New York
            "39.72,-75.28,40.14,-74.95",  # Philadelphia
            "29.52,-95.67,30.11,-95.07",  # Houston
        ]
        
        base_url = "https://overpass-api.de/api/interpreter"
        
        # –ü—Ä–æ—Å—Ç–æ–π –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π –∑–∞–ø—Ä–æ—Å
        query_template = """
        [out:json][timeout:30];
        (
          node["shop"="scrap_yard"]({bbox});
          node["amenity"="recycling"]({bbox});
          node["industrial"="scrap_yard"]({bbox});
          node[name~"scrap|metal|recycling|salvage",i]({bbox});
        );
        out center tags;
        """
        
        for i, bbox in enumerate(productive_bboxes):
            try:
                self.logger.info(f"üîç –†–µ–≥–∏–æ–Ω {i+1}/{len(productive_bboxes)}")
                query = query_template.format(bbox=bbox)
                
                response = self._make_request(base_url, data=query, method='POST')
                if response:
                    data = response.json()
                    region_businesses = self._parse_osm_fast(data)
                    businesses.extend(region_businesses)
                    
                    phones_found = sum(1 for b in region_businesses if b.get('phone'))
                    self.logger.info(f"  ‚úÖ +{len(region_businesses)} –±–∏–∑–Ω–µ—Å–æ–≤, {phones_found} —Å —Ç–µ–ª–µ—Ñ–æ–Ω–∞–º–∏")
                
                time.sleep(2)  # –ë—ã—Å—Ç—Ä—ã–µ –∑–∞–ø—Ä–æ—Å—ã
                
                if len(businesses) >= target_count:
                    break
                    
            except Exception as e:
                self.logger.warning(f"‚ùå –û—à–∏–±–∫–∞ –≤ —Ä–µ–≥–∏–æ–Ω–µ {i+1}: {e}")
                continue
        
        return businesses

    def _parse_osm_fast(self, data):
        """–ë—ã—Å—Ç—Ä—ã–π –ø–∞—Ä—Å–∏–Ω–≥ OSM —Å —Ñ–æ–∫—É—Å–æ–º –Ω–∞ —Ç–µ–ª–µ—Ñ–æ–Ω—ã"""
        businesses = []
        
        for element in data.get('elements', []):
            tags = element.get('tags', {})
            
            name = tags.get('name', '').strip()
            if not name or len(name) < 3:
                continue
            
            # –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã
            lat = element.get('lat') or (element.get('center', {}).get('lat'))
            lon = element.get('lon') or (element.get('center', {}).get('lon'))
            
            # –ê–ì–†–ï–°–°–ò–í–ù–´–ô –ø–æ–∏—Å–∫ —Ç–µ–ª–µ—Ñ–æ–Ω–∞ –≤ —Ç–µ–≥–∞—Ö
            phone = self._extract_phone_from_tags(tags)
            
            business = {
                'name': name,
                'address': self._build_address(tags),
                'city': tags.get('addr:city', ''),
                'state': tags.get('addr:state', ''),
                'zip_code': tags.get('addr:postcode', ''),
                'phone': phone,
                'website': tags.get('website', tags.get('contact:website', '')),
                'email': tags.get('email', tags.get('contact:email', '')),
                'latitude': lat,
                'longitude': lon,
                'source': 'OSM_Fast',
                'has_phone': bool(phone),
                'scraped_at': datetime.now().isoformat()
            }
            
            businesses.append(business)
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º: —Å–Ω–∞—á–∞–ª–∞ —Å —Ç–µ–ª–µ—Ñ–æ–Ω–∞–º–∏
        businesses.sort(key=lambda x: x.get('has_phone', False), reverse=True)
        return businesses

    def _extract_phone_from_tags(self, tags):
        """–ê–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–ª–µ—Ñ–æ–Ω–∞ –∏–∑ –≤—Å–µ—Ö OSM –ø–æ–ª–µ–π"""
        phone_fields = [
            'phone', 'contact:phone', 'telephone', 'contact:telephone',
            'fax', 'contact:fax', 'mobile', 'contact:mobile'
        ]
        
        for field in phone_fields:
            if field in tags and tags[field]:
                phone = self._clean_phone(tags[field])
                if phone:
                    return phone
        
        return ""

    def _aggressive_phone_mining(self, businesses):
        """–ê–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫ —Ç–µ–ª–µ—Ñ–æ–Ω–æ–≤ –¥–ª—è –±–∏–∑–Ω–µ—Å–æ–≤ –±–µ–∑ –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤"""
        self.logger.info(f"üìû –ê–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫ —Ç–µ–ª–µ—Ñ–æ–Ω–æ–≤ –¥–ª—è {len(businesses)} –±–∏–∑–Ω–µ—Å–æ–≤")
        
        enhanced = []
        
        for business in businesses:
            if business.get('phone'):  # –£–∂–µ –µ—Å—Ç—å —Ç–µ–ª–µ—Ñ–æ–Ω
                enhanced.append(business)
                continue
            
            # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ —Ç–µ–ª–µ—Ñ–æ–Ω —Ä–∞–∑–Ω—ã–º–∏ —Å–ø–æ—Å–æ–±–∞–º–∏
            enhanced_business = business.copy()
            
            # –°–ø–æ—Å–æ–± 1: –ü–æ–∏—Å–∫ —á–µ—Ä–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏–µ + –≥–æ—Ä–æ–¥
            phone = self._search_phone_by_name(business)
            if phone:
                enhanced_business['phone'] = phone
                enhanced_business['phone_source'] = 'name_search'
                enhanced_business['has_phone'] = True
            
            # –°–ø–æ—Å–æ–± 2: –ï—Å–ª–∏ –µ—Å—Ç—å —Å–∞–π—Ç, –ø–∞—Ä—Å–∏–º –µ–≥–æ
            elif enhanced_business.get('website'):
                phone = self._scrape_website_for_phone(enhanced_business['website'])
                if phone:
                    enhanced_business['phone'] = phone
                    enhanced_business['phone_source'] = 'website'
                    enhanced_business['has_phone'] = True
            
            enhanced.append(enhanced_business)
        
        phones_found = sum(1 for b in enhanced if b.get('phone'))
        self.logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ —Ç–µ–ª–µ—Ñ–æ–Ω–æ–≤: {phones_found - sum(1 for b in businesses if b.get('phone'))}")
        
        return enhanced

    def _search_phone_by_name(self, business):
        """–ü–æ–∏—Å–∫ —Ç–µ–ª–µ—Ñ–æ–Ω–∞ —á–µ—Ä–µ–∑ –ø—Ä–æ—Å—Ç–æ–π Google –ø–æ–∏—Å–∫"""
        try:
            name = business.get('name', '')
            city = business.get('city', '')
            state = business.get('state', '')
            
            if not name:
                return ""
            
            # –ü—Ä–æ—Å—Ç–æ–π –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
            query = f'"{name}" {city} {state} phone contact'
            search_url = f"https://www.google.com/search?q={quote_plus(query)}"
            
            response = self._make_request(search_url)
            if response:
                # –ò—â–µ–º —Ç–µ–ª–µ—Ñ–æ–Ω—ã –≤ HTML
                for pattern in self.phone_patterns:
                    matches = pattern.findall(response.text)
                    for match in matches:
                        phone = self._format_phone_match(match)
                        if phone:
                            return phone
            
        except Exception as e:
            self.logger.debug(f"–ü–æ–∏—Å–∫ —Ç–µ–ª–µ—Ñ–æ–Ω–∞ –ø–æ –∏–º–µ–Ω–∏ –Ω–µ—É–¥–∞—á–µ–Ω: {e}")
        
        return ""

    def _scrape_website_for_phone(self, website):
        """–ë—ã—Å—Ç—Ä—ã–π –ø–∞—Ä—Å–∏–Ω–≥ —Å–∞–π—Ç–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ç–µ–ª–µ—Ñ–æ–Ω–∞"""
        try:
            response = self._make_request(website, timeout=10)
            if not response:
                return ""
            
            # –ò—â–µ–º —Ç–µ–ª–µ—Ñ–æ–Ω—ã –≤ HTML –∏ —Ç–µ–∫—Å—Ç–µ
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # –ò—â–µ–º tel: —Å—Å—ã–ª–∫–∏
            tel_links = soup.find_all('a', href=lambda x: x and x.startswith('tel:'))
            for link in tel_links:
                phone = self._clean_phone(link.get('href', '').replace('tel:', ''))
                if phone:
                    return phone
            
            # –ò—â–µ–º –≤ —Ç–µ–∫—Å—Ç–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            page_text = response.text
            for pattern in self.phone_patterns:
                matches = pattern.findall(page_text)
                for match in matches:
                    phone = self._format_phone_match(match)
                    if phone:
                        return phone
            
        except Exception as e:
            self.logger.debug(f"–ü–∞—Ä—Å–∏–Ω–≥ —Å–∞–π—Ç–∞ –Ω–µ—É–¥–∞—á–µ–Ω: {e}")
        
        return ""

    def _show_google_instructions(self):
        """–ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –¥–ª—è Google –ø–∞—Ä—Å–∏–Ω–≥–∞"""
        print("\n" + "="*70)
        print("üîç –ù–£–ñ–ù–´ –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–ï –ö–û–ù–¢–ê–ö–¢–´ - GOOGLE –ü–ê–†–°–ò–ù–ì")
        print("="*70)
        print("1. –û—Ç–∫—Ä–æ–π—Ç–µ –±—Ä–∞—É–∑–µ—Ä –∏ –ø–µ—Ä–µ–π–¥–∏—Ç–µ –Ω–∞ google.com")
        print("2. –í–≤–µ–¥–∏—Ç–µ –∑–∞–ø—Ä–æ—Å: scrap metal recycling \"–≤–∞—à –≥–æ—Ä–æ–¥\"")
        print("3. –ü–µ—Ä–µ–π–¥–∏—Ç–µ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã 2-5 (—Ç–∞–º –∫–æ–º–ø–∞–Ω–∏–∏ —Å –Ω–∏–∑–∫–∏–º–∏ –ø–æ–∑–∏—Ü–∏—è–º–∏)")
        print("4. –û—Ç–∫—Ä–æ–π—Ç–µ Developer Tools (F12) ‚Üí Console")
        print("5. –°–∫–æ–ø–∏—Ä—É–π—Ç–µ –∏ –≤—Å—Ç–∞–≤—å—Ç–µ —ç—Ç–æ—Ç JavaScript:")
        print("\n" + "-"*50)
        print(self.google_js_script)
        print("-"*50)
        print("\n6. –°–∫–æ–ø–∏—Ä—É–π—Ç–µ JSON –∏–∑ –æ–∫–Ω–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–∏—Ç–µ –∫–∞–∫ 'google_links.json'")
        print("7. –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç–µ –ø–∞—Ä—Å–µ—Ä - –æ–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∞–µ—Ç —Å—Å—ã–ª–∫–∏")
        print("="*70)

    def _process_google_links(self, json_file):
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å—Å—ã–ª–∫–∏ –∏–∑ Google"""
        businesses = []
        
        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                google_links = json.load(f)
            
            self.logger.info(f"üîç –û–±—Ä–∞–±–æ—Ç–∫–∞ {len(google_links)} —Å—Å—ã–ª–æ–∫ –∏–∑ Google")
            
            for link_data in google_links:
                url = link_data.get('url', '')
                if not url:
                    continue
                
                business = self._extract_business_from_url(url, link_data)
                if business and business.get('phone'):  # –¢–æ–ª—å–∫–æ —Å —Ç–µ–ª–µ—Ñ–æ–Ω–∞–º–∏
                    businesses.append(business)
            
            self.logger.info(f"‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(businesses)} –±–∏–∑–Ω–µ—Å–æ–≤ —Å —Ç–µ–ª–µ—Ñ–æ–Ω–∞–º–∏ –∏–∑ Google")
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ Google —Å—Å—ã–ª–æ–∫: {e}")
        
        return businesses

    def _extract_business_from_url(self, url, link_data):
        """–ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –±–∏–∑–Ω–µ—Å–∞ —Å —Å–∞–π—Ç–∞"""
        try:
            response = self._make_request(url, timeout=15)
            if not response:
                return None
            
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # –ò—â–µ–º —Ç–µ–ª–µ—Ñ–æ–Ω
            phone = self._scrape_website_for_phone(url)
            if not phone:  # –ï—Å–ª–∏ –Ω–µ—Ç —Ç–µ–ª–µ—Ñ–æ–Ω–∞, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                return None
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            business = {
                'name': link_data.get('title', 'Unknown Business'),
                'website': url,
                'phone': phone,
                'email': self._extract_email_from_page(soup),
                'address': self._extract_address_from_page(soup),
                'source': 'Google_Links',
                'google_position': link_data.get('position', 0),
                'has_phone': True,
                'scraped_at': datetime.now().isoformat()
            }
            
            return business
            
        except Exception as e:
            self.logger.debug(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Å {url}: {e}")
            return None

    def _extract_email_from_page(self, soup):
        """–ë—ã—Å—Ç—Ä–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ email"""
        email_pattern = re.compile(r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b')
        
        # –ò—â–µ–º –≤ —Ç–µ–∫—Å—Ç–µ
        text = soup.get_text()
        emails = email_pattern.findall(text)
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º
        for email in emails:
            if not any(skip in email.lower() for skip in ['example.com', 'test.com', 'google.com']):
                return email
        
        return ""

    def _extract_address_from_page(self, soup):
        """–ë—ã—Å—Ç—Ä–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∞–¥—Ä–µ—Å–∞"""
        selectors = ['.address', '.location', '[itemtype*="PostalAddress"]']
        
        for selector in selectors:
            element = soup.select_one(selector)
            if element:
                address = element.get_text().strip()
                if any(word in address.lower() for word in ['street', 'ave', 'road', 'drive']):
                    return address[:150]
        
        return ""

    def _format_phone_match(self, match):
        """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–π —Ç–µ–ª–µ—Ñ–æ–Ω"""
        if isinstance(match, tuple) and len(match) >= 3:
            return f"({match[0]}) {match[1]}-{match[2]}"
        elif isinstance(match, str):
            return self._clean_phone(match)
        return ""

    def _clean_phone(self, phone):
        """–û—á–∏—Å—Ç–∫–∞ –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–µ–ª–µ—Ñ–æ–Ω–∞"""
        if not phone:
            return ""
        
        digits = re.sub(r'\D', '', phone)
        
        if len(digits) == 10:
            return f"({digits[:3]}) {digits[3:6]}-{digits[6:]}"
        elif len(digits) == 11 and digits[0] == '1':
            return f"({digits[1:4]}) {digits[4:7]}-{digits[7:]}"
        
        return ""

    def _build_address(self, tags):
        """–ë—ã—Å—Ç—Ä–æ–µ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∞–¥—Ä–µ—Å–∞"""
        parts = []
        if tags.get('addr:housenumber'):
            parts.append(tags['addr:housenumber'])
        if tags.get('addr:street'):
            parts.append(tags['addr:street'])
        return ' '.join(parts) if parts else ""

    def _calculate_phone_percentage(self, businesses):
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç —Å —Ç–µ–ª–µ—Ñ–æ–Ω–∞–º–∏"""
        if not businesses:
            return 0
        return (sum(1 for b in businesses if b.get('phone')) / len(businesses)) * 100

    def _make_request(self, url, params=None, data=None, method='GET', timeout=30):
        """–ë—ã—Å—Ç—Ä—ã–µ HTTP –∑–∞–ø—Ä–æ—Å—ã"""
        try:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            
            if method == 'POST':
                response = self.session.post(url, headers=headers, data=data, timeout=timeout)
            else:
                response = self.session.get(url, headers=headers, params=params, timeout=timeout)
            
            if response.status_code == 200:
                return response
            
        except Exception as e:
            self.logger.debug(f"–ó–∞–ø—Ä–æ—Å –Ω–µ—É–¥–∞—á–µ–Ω: {e}")
        
        return None

    def export_results(self, output_dir="output"):
        """–ë—ã—Å—Ç—Ä—ã–π —ç–∫—Å–ø–æ—Ä—Ç —Å –∞–∫—Ü–µ–Ω—Ç–æ–º –Ω–∞ –∫–æ–Ω—Ç–∞–∫—Ç—ã"""
        if not self.results:
            return None
        
        os.makedirs(output_dir, exist_ok=True)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        total = len(self.results)
        with_phones = sum(1 for b in self.results if b.get('phone'))
        phone_percentage = (with_phones / total) * 100 if total > 0 else 0
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º: —Å–Ω–∞—á–∞–ª–∞ —Å —Ç–µ–ª–µ—Ñ–æ–Ω–∞–º–∏
        sorted_results = sorted(self.results, key=lambda x: bool(x.get('phone')), reverse=True)
        
        # CSV —ç–∫—Å–ø–æ—Ä—Ç
        df = pd.DataFrame(sorted_results)
        csv_file = os.path.join(output_dir, f"optimized_contacts_{timestamp}.csv")
        df.to_csv(csv_file, index=False)
        
        # –ü—Ä–æ—Å—Ç–æ–π –æ—Ç—á–µ—Ç
        report_file = os.path.join(output_dir, f"contact_report_{timestamp}.txt")
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("üìû –û–¢–ß–ï–¢ –ü–û –ö–û–ù–¢–ê–ö–¢–ê–ú\n")
            f.write("=" * 40 + "\n\n")
            f.write(f"–í—Å–µ–≥–æ –±–∏–∑–Ω–µ—Å–æ–≤: {total}\n")
            f.write(f"–° —Ç–µ–ª–µ—Ñ–æ–Ω–∞–º–∏: {with_phones} ({phone_percentage:.1f}%)\n")
            f.write(f"–¶–µ–ª—å –¥–æ—Å—Ç–∏–≥–Ω—É—Ç–∞: {'‚úÖ –î–ê' if phone_percentage >= self.MIN_PHONES_PERCENTAGE else '‚ùå –ù–ï–¢'}\n\n")
            
            if phone_percentage >= self.MIN_PHONES_PERCENTAGE:
                f.write("üéâ –û–¢–õ–ò–ß–ù–û! –ú–æ–∂–Ω–æ –Ω–∞—á–∏–Ω–∞—Ç—å –∑–≤–æ–Ω–∫–∏!\n")
            else:
                f.write("‚ö†Ô∏è –ù—É–∂–Ω–æ –±–æ–ª—å—à–µ –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ Google –ø–∞—Ä—Å–∏–Ω–≥.\n")
        
        self.logger.info(f"‚úÖ –≠–∫—Å–ø–æ—Ä—Ç –∑–∞–≤–µ—Ä—à–µ–Ω:")
        self.logger.info(f"  ‚Ä¢ CSV: {csv_file}")
        self.logger.info(f"  ‚Ä¢ –û—Ç—á–µ—Ç: {report_file}")
        self.logger.info(f"üìä –ò–¢–û–ì: {phone_percentage:.1f}% —Å —Ç–µ–ª–µ—Ñ–æ–Ω–∞–º–∏")
        
        return {
            'csv_file': csv_file,
            'total_businesses': total,
            'businesses_with_phones': with_phones,
            'phone_percentage': phone_percentage,
            'success': phone_percentage >= self.MIN_PHONES_PERCENTAGE
        }

def main():
    print("‚ö° –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–´–ô –ü–ê–†–°–ï–† - –ë—ã—Å—Ç—Ä—ã–π —Å–±–æ—Ä –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤")
    print("=" * 60)
    print("üéØ –ü–†–ò–û–†–ò–¢–ï–¢: –ú–∞–∫—Å–∏–º—É–º —Ç–µ–ª–µ—Ñ–æ–Ω–æ–≤, –º–∏–Ω–∏–º—É–º –≤—Ä–µ–º–µ–Ω–∏")
    print("üîß –ë–ï–ó SELENIUM: –¢–æ–ª—å–∫–æ –±—ã—Å—Ç—Ä—ã–µ HTTP –∑–∞–ø—Ä–æ—Å—ã")
    print("ü§ù –ì–ò–ë–†–ò–î: OSM + –ø–æ–ª—É–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π Google")
    
    scraper = OptimizedScraper()
    
    try:
        target = int(input("\n–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–∏–∑–Ω–µ—Å–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 100): ") or "100")
        
        print(f"\n‚ö° –ó–∞–ø—É—Å–∫ –±—ã—Å—Ç—Ä–æ–≥–æ —Å–±–æ—Ä–∞ –¥–ª—è {target} –±–∏–∑–Ω–µ—Å–æ–≤...")
        print("–ü—Ä–æ—Ü–µ—Å—Å:")
        print("1. üìç –ë—ã—Å—Ç—Ä—ã–π OSM —Å–±–æ—Ä –∏–∑ –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω—ã—Ö —Ä–µ–≥–∏–æ–Ω–æ–≤")
        print("2. üìû –ê–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫ —Ç–µ–ª–µ—Ñ–æ–Ω–æ–≤")
        print("3. üîç –ü—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ - –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –¥–ª—è Google")
        
        start_time = time.time()
        results = scraper.collect_with_contact_priority(target)
        elapsed = time.time() - start_time
        
        if results:
            phone_count = sum(1 for b in results if b.get('phone'))
            phone_percentage = (phone_count / len(results)) * 100
            
            print(f"\n‚úÖ –°–±–æ—Ä –∑–∞–≤–µ—Ä—à–µ–Ω –∑–∞ {elapsed:.1f} —Å–µ–∫—É–Ω–¥!")
            print(f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç: {len(results)} –±–∏–∑–Ω–µ—Å–æ–≤")
            print(f"üìû –° —Ç–µ–ª–µ—Ñ–æ–Ω–∞–º–∏: {phone_count} ({phone_percentage:.1f}%)")
            
            export_info = scraper.export_results()
            if export_info:
                print(f"\nüìÅ –§–∞–π–ª—ã —Å–æ–∑–¥–∞–Ω—ã:")
                print(f"  ‚Ä¢ {export_info['csv_file']}")
                
                if export_info['success']:
                    print(f"\nüéâ –£–°–ü–ï–•! –¶–µ–ª—å –¥–æ—Å—Ç–∏–≥–Ω—É—Ç–∞ - –º–æ–∂–Ω–æ –Ω–∞—á–∏–Ω–∞—Ç—å outreach!")
                else:
                    print(f"\n‚ö†Ô∏è –ù—É–∂–Ω–æ –±–æ–ª—å—à–µ –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤. –°–ª–µ–¥—É–π—Ç–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º –¥–ª—è Google –ø–∞—Ä—Å–∏–Ω–≥–∞.")
        else:
            print("‚ùå –î–∞–Ω–Ω—ã–µ –Ω–µ —Å–æ–±—Ä–∞–Ω—ã")
            
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è –ü—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")

if __name__ == "__main__":
    main() 